{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "0505_shoulder_classification_datapreprocess.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chan-han0101/TT_ai-project/blob/main/0505_shoulder_classification_datapreprocess.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAHkfWvnejbK"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahnuW8rfKSkZ"
      },
      "source": [
        "#記得掛載雲端硬碟 \n",
        "from zipfile import ZipFile\n",
        "path = \"/content/drive/MyDrive/after_openpose_onchair/out_resize256x256_0_5144_json.zip\"\n",
        "f = ZipFile(path)\n",
        "# f.extractall() 小括號是直接解壓縮在同一層\n",
        "f.extractall()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNoY0fsKOqw3"
      },
      "source": [
        "# img_fn_df 圖片名稱DataFrame\n",
        "import glob\n",
        "import json, codecs\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "fn_dic = {\"img_name\":[]}\n",
        "# fn_dic_2 = []\n",
        "paths = sorted(glob.glob(\"/content/out_resize256x256_0_5144_json/*\"))\n",
        "for path in paths:\n",
        "  fn_type = path.split(\"/\")[-1]\n",
        "  fn = fn_type.split(\".\")[0]\n",
        "  fn_dic[\"img_name\"].append(fn)\n",
        "  # fn_dic_2.append(fn)\n",
        "# print(fn_dic)\n",
        "fn_dic_df = pd.DataFrame(fn_dic)\n",
        "fn_dic_df\n",
        "# print(fn_dic_2)\n",
        "\n",
        "\n",
        "# file_path = \"/content/1162.json\"\n",
        "# for i in range(len(fs))\n",
        "# obj_text = codecs.open(paths[0], 'r', encoding='utf-8').read()\n",
        "# b_new = json.loads(obj_text)\n",
        "# a_new = np.array(b_new)\n",
        "# a_new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHwkV0stfoHk"
      },
      "source": [
        "# ans_df  驗證資料DataFrame\n",
        "import os\n",
        "base = \"/content/drive/MyDrive/after_openpose_onchair/wrong_total_sit_value_0_5144.csv\"\n",
        "sitting_csv = pd.read_csv(base, sep=\",\")\n",
        "ans_df = pd.DataFrame(sitting_csv)\n",
        "ans_df = ans_df.drop([\"img_name\"], axis=1)\n",
        "\n",
        "# ans_df[\"class_name\"] = \"\"\n",
        "ans_df\n",
        "# ans = df[:1]\n",
        "# ans = ans.drop([\"img_name\"], axis=1)\n",
        "# ans\n",
        "# print(type(sitting_csv)\n",
        "# np.array(sitting_csv)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFlCfoeQl6ll"
      },
      "source": [
        "# keypoints_36_combine_df 關節節點DataFrame\n",
        "import json, codecs\n",
        "import numpy as np\n",
        "columns ={\n",
        "     \"coco_col\":['Nose_x', 'Nose_y', 'Neck_x', 'Neck_y',\n",
        "           'R-Sho_x', 'R-Sho_y', 'R-Elb_x', 'R-Elb_y',\n",
        "           'R-Wr_x', 'R-Wr_y', 'L-Sho_x', 'L-Sho_y', \n",
        "           'L-Elb_x', 'L-Elb_y', 'L-Wr_x', 'L-Wr_y',\n",
        "           'R-Hip_x', 'R-Hip_y', 'R-Knee_x', 'R-Knee_y',\n",
        "           'R-Ank_x', 'R-Ank_y', 'L-Hip_x', 'L-Hip_y',\n",
        "           'L-Knee_x', 'L-Knee_y', 'L-Ank_x', 'L-Ank_y',\n",
        "           'R-Eye_x', 'R-Eye_y', 'L-Eye_x', 'L-Eye_y',\n",
        "           'R-Ear_x', 'R-Ear_y', 'L-Ear_x', 'L-Ear_y']\n",
        "    }\n",
        "fn_list = fn_dic[\"img_name\"]\n",
        "# print(fn_list) 印0004, 0006...\n",
        "\n",
        "# 運用globals()[] 全域變數：做成動態的變數名。\n",
        "n_fn_list = []\n",
        "for fn in fn_list:\n",
        "  # print(fn)\n",
        "  obj_text = codecs.open(\"/content/out_resize256x256_0_5144_json/\"+ fn + \".json\", 'r', encoding='utf-8').read()\n",
        "  b_new = json.loads(obj_text)\n",
        "  a_new = np.array(b_new)\n",
        "  a_new = a_new.reshape(1,36)\n",
        "  # print(a_new)\n",
        "  globals()[\"key_point_36\"+ fn +\"_df\"] = pd.DataFrame(a_new, columns = columns[\"coco_col\"])\n",
        "  # print(globals()[\"key_point_36\"+ fn +\"_df\"])\n",
        "  n_fn_list.append(globals()[\"key_point_36\"+ fn +\"_df\"])\n",
        "# print(n_fn_list)\n",
        "\n",
        "# pd.concat([key_point_36_0004_df, key_point_36_0006_df, key_point_36_0008_df])\n",
        "key_point_36_combine_df = pd.concat(n_fn_list)\n",
        "key_point_36_combine_df\n",
        "\n",
        "# bond.reset_index(inplace=True)\n",
        "key_point_36_combine_df = key_point_36_combine_df.reset_index()\n",
        "key_point_36_combine_df\n",
        "\n",
        "# df.drop(columns=['B', 'C'])\n",
        "# df.drop(['B', 'C'], axis=1)\n",
        "key_point_36_combine_df = key_point_36_combine_df.drop(columns=['index'])\n",
        "key_point_36_combine_df\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WST_fOH6dS61"
      },
      "source": [
        "# keypoints_36_combine_df 關節節點DataFrame\n",
        "import json, codecs\n",
        "import numpy as np\n",
        "columns ={\n",
        "     \"coco_col\":['Nose_x', 'Nose_y', 'Neck_x', 'Neck_y',\n",
        "           'R-Sho_x', 'R-Sho_y', 'R-Elb_x', 'R-Elb_y',\n",
        "           'R-Wr_x', 'R-Wr_y', 'L-Sho_x', 'L-Sho_y', \n",
        "           'L-Elb_x', 'L-Elb_y', 'L-Wr_x', 'L-Wr_y',\n",
        "           'R-Hip_x', 'R-Hip_y', 'R-Knee_x', 'R-Knee_y',\n",
        "           'R-Ank_x', 'R-Ank_y', 'L-Hip_x', 'L-Hip_y',\n",
        "           'L-Knee_x', 'L-Knee_y', 'L-Ank_x', 'L-Ank_y',\n",
        "           'R-Eye_x', 'R-Eye_y', 'L-Eye_x', 'L-Eye_y',\n",
        "           'R-Ear_x', 'R-Ear_y', 'L-Ear_x', 'L-Ear_y']\n",
        "    }\n",
        "fn_list = fn_dic[\"img_name\"]\n",
        "# print(fn_list) 印0004, 0006...\n",
        "\n",
        "# 運用globals()[] 全域變數：做成動態的變數名。\n",
        "n_fn_list = []\n",
        "for fn in fn_list:\n",
        "  # print(fn)\n",
        "  obj_text = codecs.open(\"/content/out_resize256x256_0_5144_json/\"+ fn + \".json\", 'r', encoding='utf-8').read()\n",
        "  b_new = json.loads(obj_text)\n",
        "  a_new = np.array(b_new)\n",
        "  a_new = a_new.reshape(1,36)\n",
        "  # print(a_new)\n",
        "  globals()[\"key_point_36\"+ fn +\"_df\"] = pd.DataFrame(a_new, columns = columns[\"coco_col\"])\n",
        "  # print(globals()[\"key_point_36\"+ fn +\"_df\"])\n",
        "  n_fn_list.append(globals()[\"key_point_36\"+ fn +\"_df\"])\n",
        "# print(n_fn_list)\n",
        "\n",
        "# pd.concat([key_point_36_0004_df, key_point_36_0006_df, key_point_36_0008_df])\n",
        "key_point_36_combine_df = pd.concat(n_fn_list)\n",
        "key_point_36_combine_df\n",
        "\n",
        "# bond.reset_index(inplace=True)\n",
        "key_point_36_combine_df = key_point_36_combine_df.reset_index()\n",
        "key_point_36_combine_df\n",
        "\n",
        "# df.drop(columns=['B', 'C'])\n",
        "# df.drop(['B', 'C'], axis=1)\n",
        "key_point_36_combine_df = key_point_36_combine_df.drop(columns=['index'])\n",
        "key_point_36_combine_df\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36ogQZeYqQau"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import csv\n",
        "coco_col = ['Nose_x', 'Nose_y', 'Neck_x', 'Neck_y',\n",
        "    'R-Sho_x', 'R-Sho_y', 'R-Elb_x', 'R-Elb_y',\n",
        "    'R-Wr_x', 'R-Wr_y', 'L-Sho_x', 'L-Sho_y', \n",
        "    'L-Elb_x', 'L-Elb_y', 'L-Wr_x', 'L-Wr_y',\n",
        "    'R-Hip_x', 'R-Hip_y', 'R-Knee_x', 'R-Knee_y',\n",
        "    'R-Ank_x', 'R-Ank_y', 'L-Hip_x', 'L-Hip_y',\n",
        "    'L-Knee_x', 'L-Knee_y', 'L-Ank_x', 'L-Ank_y',\n",
        "    'R-Eye_x', 'R-Eye_y', 'L-Eye_x', 'L-Eye_y',\n",
        "    'R-Ear_x', 'R-Ear_y', 'L-Ear_x', 'L-Ear_y']\n",
        "coco_col_x = ['Nose_x', 'Neck_x',\n",
        "      'R-Sho_x', 'R-Elb_x',\n",
        "      'R-Wr_x', 'L-Sho_x',\n",
        "      'L-Elb_x', 'L-Wr_x', \n",
        "      'R-Hip_x', 'R-Knee_x', \n",
        "      'R-Ank_x', 'L-Hip_x',\n",
        "      'L-Knee_x', 'L-Ank_x',\n",
        "      'R-Eye_x', 'L-Eye_x',\n",
        "      'R-Ear_x', 'L-Ear_x', ]\n",
        "coco_col_y =['Nose_y','Neck_y',\n",
        "        'R-Sho_y','R-Elb_y',\n",
        "        'R-Wr_y','L-Sho_y',\n",
        "        'L-Elb_y','L-Wr_y',\n",
        "        'R-Hip_y','R-Knee_y',\n",
        "        'R-Ank_y','L-Hip_y',\n",
        "        'L-Knee_y','L-Ank_y',\n",
        "        'R-Eye_y','L-Eye_y',\n",
        "        'R-Ear_y','L-Ear_y']\n",
        "base = \"./sample_data\"\n",
        "\n",
        "key_point_36_combine_df.to_excel(base +\"/out.xlsx\")\n",
        "\n",
        "# key_point_36_combine_normalize_preprocess\n",
        "\n",
        "key_point_36_combine_columns_list = columns[\"coco_col\"]\n",
        "\n",
        "key_point_36_combine_row_list = []\n",
        "len(key_point_36_combine_df)\n",
        "\n",
        "# key_point_36_combine_row_list = []\n",
        "# len(key_point_36_combine_df)\n",
        "# globals()[\"key_point_36_combine_row\"+ str(i) +\"_df\"][\"Neck_x\"]\n",
        "\n",
        "for i in range(len(key_point_36_combine_df)):\n",
        "  globals()[\"key_point_36_combine_row\"+ str(i) +\"_df\"] = key_point_36_combine_df[i:i+1]\n",
        "  # key_point_36_combine_row0_df\n",
        "\n",
        "  \n",
        "  for key_point_36_combine_column in coco_col:\n",
        "    if key_point_36_combine_column == \"Neck_x\":\n",
        "      continue\n",
        "    elif key_point_36_combine_column == \"Neck_y\":\n",
        "      continue\n",
        "    elif \"x\" in key_point_36_combine_column:\n",
        "        globals()[\"key_point_36_combine_row\"+ str(i) +\"_df\"][key_point_36_combine_column] = globals()[\"key_point_36_combine_row\"+ str(i) +\"_df\"][key_point_36_combine_column] - globals()[\"key_point_36_combine_row\"+ str(i) +\"_df\"][\"Neck_x\"]\n",
        "    elif \"y\" in key_point_36_combine_column:\n",
        "        globals()[\"key_point_36_combine_row\"+ str(i) +\"_df\"][key_point_36_combine_column] = globals()[\"key_point_36_combine_row\"+ str(i) +\"_df\"][key_point_36_combine_column] - globals()[\"key_point_36_combine_row\"+ str(i) +\"_df\"][\"Neck_y\"]\n",
        "  key_point_36_combine_row_list.append(globals()[\"key_point_36_combine_row\"+ str(i) +\"_df\"])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2AW_Pacv1Sa"
      },
      "source": [
        "# normalize\n",
        "key_point_36_combine_norm = pd.concat(key_point_36_combine_row_list)\n",
        "key_point_36_combine_norm.loc[:,[\"Neck_x\",\"Neck_y\"]] = 0\n",
        "key_point_36_combine_norm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mb80G03d9LV-"
      },
      "source": [
        "# key_point_36_combine_df, ans_df\n",
        "# pd.concat([key_point_36_combine_df, ans_df], axis=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRGp-e1Hci0U"
      },
      "source": [
        "# list1 = ['A', 'B', 'C', 'D']\n",
        "# for i in list1:\n",
        "#   globals()[i] = []\n",
        "# A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1nt0dGqo7KK"
      },
      "source": [
        "#fn_dic + key_point_36\n",
        "# res = pd.concat([df1,df2,df3],axis=0)\n",
        "# pd.concat([fn_dic_df, key_point_36_df] , axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypuE1motpuEd"
      },
      "source": [
        "# test\n",
        "# from PIL import Image\n",
        "\n",
        "# img = Image.open(\"/content/4.jpg\")\n",
        "# (w, h) = img.size\n",
        "# print('w=%d, h=%d', w, h)\n",
        "# img.show()\n",
        "\n",
        "# new_img = img.resize((256, 256))\n",
        "# new_img.show()\n",
        "# new_img.save(\"4-256x256.jpg\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14FzaKmTjNY0"
      },
      "source": [
        "ans_df[\"shoulder\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JKNPXAbkOse"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(np.array(key_point_36_combine_df),\n",
        "                              np.array(ans_df[\"shoulder\"]),\n",
        "                             test_size=0.1)\n",
        "x_train, x_test, y_train, y_test  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VA70hxP3lYS_"
      },
      "source": [
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9gMyAa3ltgl"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "clf = DecisionTreeClassifier(max_depth=3)\n",
        "clf.fit(x_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSU0F-gkmgbA"
      },
      "source": [
        "key_point_36_combine_df.columns\n",
        "ans_df[\"shoulder\"].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9XzaPVikUY1"
      },
      "source": [
        "class_key_list=[\"head_correct\", \"head_wrong\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwBzoogolvbi"
      },
      "source": [
        "from sklearn.tree import plot_tree\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(128, 128))\n",
        "#figsize 這邊指畫布的height, weight\n",
        "plot_tree(clf,\n",
        "     max_depth=2,\n",
        "     feature_names=key_point_36_combine_df.columns,\n",
        "     class_names=class_key_list,\n",
        "     filled=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFcaXxZXmdQd"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "pre = clf.predict(x_test)\n",
        "accuracy_score(pre, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7y4D_lYCMb8z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}